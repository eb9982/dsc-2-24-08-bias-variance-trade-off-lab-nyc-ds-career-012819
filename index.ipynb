{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias-Variance Trade-Off - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you'll practice your knowledge on the bias-variance trade-off!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be able to: \n",
    "- Look at an example where Polynomial regression leads to overfitting\n",
    "- Understand how bias-variance trade-off relates to underfitting and overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll try to predict some movie revenues based on certain factors, such as ratings and movie year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>domgross</th>\n",
       "      <th>title</th>\n",
       "      <th>Response_Json</th>\n",
       "      <th>Year</th>\n",
       "      <th>imdbRating</th>\n",
       "      <th>Metascore</th>\n",
       "      <th>imdbVotes</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13000000</td>\n",
       "      <td>25682380</td>\n",
       "      <td>21 &amp;amp; Over</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>6.8</td>\n",
       "      <td>48</td>\n",
       "      <td>206513</td>\n",
       "      <td>4.912759e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45658735</td>\n",
       "      <td>13414714</td>\n",
       "      <td>Dredd 3D</td>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.267265e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000000</td>\n",
       "      <td>53107035</td>\n",
       "      <td>12 Years a Slave</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>8.1</td>\n",
       "      <td>96</td>\n",
       "      <td>537525</td>\n",
       "      <td>1.626624e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61000000</td>\n",
       "      <td>75612460</td>\n",
       "      <td>2 Guns</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>6.7</td>\n",
       "      <td>55</td>\n",
       "      <td>173726</td>\n",
       "      <td>7.723381e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40000000</td>\n",
       "      <td>95020213</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>2013</td>\n",
       "      <td>7.5</td>\n",
       "      <td>62</td>\n",
       "      <td>74170</td>\n",
       "      <td>4.151958e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     budget  domgross             title  Response_Json  Year  imdbRating  \\\n",
       "0  13000000  25682380     21 &amp; Over              0  2008         6.8   \n",
       "1  45658735  13414714          Dredd 3D              0  2012         0.0   \n",
       "2  20000000  53107035  12 Years a Slave              0  2013         8.1   \n",
       "3  61000000  75612460            2 Guns              0  2013         6.7   \n",
       "4  40000000  95020213                42              0  2013         7.5   \n",
       "\n",
       "   Metascore  imdbVotes         Model  \n",
       "0         48     206513  4.912759e+07  \n",
       "1          0          0  2.267265e+05  \n",
       "2         96     537525  1.626624e+08  \n",
       "3         55     173726  7.723381e+07  \n",
       "4         62      74170  4.151958e+07  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df = pd.read_excel('./movie_data_detailed_with_ols.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/learn-env/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>imdbRating</th>\n",
       "      <th>Metascore</th>\n",
       "      <th>imdbVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.034169</td>\n",
       "      <td>0.839506</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.384192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.182956</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.066059</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.252847</td>\n",
       "      <td>0.827160</td>\n",
       "      <td>0.572917</td>\n",
       "      <td>0.323196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.157175</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>0.137984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     budget  imdbRating  Metascore  imdbVotes\n",
       "0  0.034169    0.839506   0.500000   0.384192\n",
       "1  0.182956    0.000000   0.000000   0.000000\n",
       "2  0.066059    1.000000   1.000000   1.000000\n",
       "3  0.252847    0.827160   0.572917   0.323196\n",
       "4  0.157175    0.925926   0.645833   0.137984"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only keep four predictors and transform the with MinMaxScaler\n",
    "\n",
    "scale = MinMaxScaler()\n",
    "target = df[['domgross']]\n",
    "df = df[[ \"budget\", \"imdbRating\", \"Metascore\", \"imdbVotes\"]]\n",
    "transformed = scale.fit_transform(df)\n",
    "pd_df = pd.DataFrame(transformed, columns = df.columns)\n",
    "pd_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into a test and train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# domgross is the outcome variable\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n",
    "X_train,X_test,y_train,y_test = train_test_split(pd_df,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a regression model to the training data and look at the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4771810202933412"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import *\n",
    "rfr = Ran().fit(X_train,y_train)\n",
    "rfr.score(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the training predictions against the actual data (y_hat_train vs. y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot our result for the train data. Because we have multiple predictors, we can not simply plot the income variable X on the x-axis and target y on the y-axis. Lets plot \n",
    "- a line showing the diagonal of y_train. The actual y_train values are on this line\n",
    "- next, make a scatter plot that takes the actual y_train on the x-axis and the predictions using the model on the y-axis. You will see points scattered around the line. The horizontal distances between the points and the lines are the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f36bf73e320>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.scatter(y_train,rfr.predict(X_train))\n",
    "plt.plot(y_train, y_train, label='Actual Data')\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the test predictions against the actual data (y_hat_test vs. y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same thing for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the bias\n",
    "Write a formula to calculate the bias of a models predictions given the actual data: $Bias(\\hat{f}(x)) = E[\\hat{f}(x)-f(x)]$   \n",
    "(The expected value can simply be taken as the mean or average value.)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def bias(y, y_hat):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the variance\n",
    "Write a formula to calculate the variance of a model's predictions: $Var(\\hat{f}(x)) = E[\\hat{f}(x)^2] - \\big(E[\\hat{f}(x)]\\big)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance(y_hat):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use your functions to calculate the bias and variance of your model. Do this seperately for the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for train set bias and variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for test set bias and variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe in words what these numbers can tell you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your description here (this cell is formatted using markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfit a new model by creating additional features by raising current features to various powers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `PolynomialFeatures` with degree 3. \n",
    "\n",
    "**Important note:** By including this, you don't only take polynomials of single variables, but you also combine variables, eg:\n",
    "\n",
    "$ \\text{Budget} * \\text{MetaScore} ^ 2 $\n",
    "\n",
    "What you're essentially doing is taking interactions and creating polynomials at the same time! Have a look at how many columns we get using `np.shape`. Quite a few!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot your overfitted model's training predictions against the actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, we almost get a perfect fit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the bias and variance for the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot your overfitted model's test predictions against the actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Calculate the bias and variance for the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe what you notice about the bias and variance statistics for your overfit model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bias and variance for the test set both increased drastically in the overfit model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Up - Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab we went from 4 predictors to 35 by adding polynomials and interactions, using `PolynomialFeatures`. That being said, where 35 leads to overfitting, there are probably ways to improve by just adding a few polynomials. Feel free to experiment and see how bias and variance improve!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab gave you insight in how bias and variance change for a training and test set by using a pretty \"simple\" model, and a very complex model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
